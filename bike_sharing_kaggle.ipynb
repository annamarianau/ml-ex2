{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bike sharing (Kaggle) ()\n",
    "- https://www.kaggle.com/c/184702-tu-ml-ws-18-bike-sharing#_=_\n",
    "- large samples (train = 8690), small dimension (15)\n",
    "- attribute characteristics: numeric, date?\n",
    "\n",
    "## with preprocessing\n",
    "- prepocessing: scale (standardize)\n",
    "- with 50 samples: \n",
    "    - 13.559 s\n",
    "    - {'max_depth': 5, 'min_samples_split': 15, 'n_estimators': 350}\n",
    "    - RMSE: 89.9571\n",
    "    - Kaggle: 143.91026\n",
    "- with 150 samples: \n",
    "    - 25.025 s\n",
    "    - {'max_depth': 5, 'min_samples_split': 15, 'n_estimators': 350}\n",
    "    - RMSE: 118.99678\n",
    "    - Kaggle: 128.42365\n",
    "- with 500 samples: \n",
    "    - 74.803 s\n",
    "    - {'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 350}\n",
    "    - RMSE: 78.88731\n",
    "    - Kaggle: 128.39004\n",
    "- with 2000 samples:\n",
    "    - 431.691 s\n",
    "    - {'max_depth': 10, 'min_samples_split': 15, 'n_estimators': 350}\n",
    "    - RMSE: 54.24448\n",
    "    - Kaggle: 54.09653\n",
    "- with all samples:\n",
    "    - 4361.643 s\n",
    "    - {'max_depth': 10, 'min_samples_split': 15, 'n_estimators': 350}\n",
    "    - RMSE: 43.12057\n",
    "    - __Kaggle: 43.16327__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "%run './base.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read train data\n",
    "train = pd.read_csv('./data/bike_sharing_kaggle/bikeSharing.shuf.train.csv').drop(['dteday'], axis=1)\n",
    "train.set_index(['id'], inplace=True)\n",
    "# extract, then drop 'Grade' col\n",
    "train_target = train[['cnt']]\n",
    "train.drop(['cnt'], axis='columns', inplace=True)\n",
    "\n",
    "# read test data\n",
    "test = pd.read_csv('./data/bike_sharing_kaggle/bikeSharing.shuf.test.csv').drop(['dteday'], axis=1)\n",
    "test.set_index(['id'], inplace=True)\n",
    "\n",
    "# scale train and test data\n",
    "train_s, test_s = scale_data(train, test)\n",
    "\n",
    "X_train = train_s\n",
    "y_train = train_target\n",
    "X_test = test_s\n",
    "\n",
    "#display(train_s)\n",
    "#display(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 value for model: 0.38403134493881663\n",
      "Saved as lr_2019-01-01 23:47:28.062938.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/base.py:485: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  linalg.lstsq(X, y)\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "reg = linear_reg(X_train, y_train)\n",
    "result = pd.DataFrame(reg.predict(X_test), columns=['cnt'])\n",
    "\n",
    "# join id col\n",
    "result = pd.concat([X_test.reset_index()[['id']], result], axis='columns')\n",
    "\n",
    "# Save result\n",
    "filename = f'''lr_{dt.datetime.now()}.csv'''\n",
    "\n",
    "result.to_csv('./predictions/bike_sharing_kaggle/' + filename, sep = \",\", index=False)\n",
    "print(f'''Saved as {filename}''')\n",
    "\n",
    "#display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch initializing...\n",
      "SVR model in training...\n"
     ]
    }
   ],
   "source": [
    "# SVR\n",
    "# params\n",
    "param_grid = {\n",
    "    'C': np.linspace(.2,1,5),\n",
    "    'kernel': ['linear'],#, 'rbf', 'sigmoid', 'poly'], # poly very slow\n",
    "    'epsilon': np.linspace(0,.5,6),\n",
    "    'gamma': ['auto']#, 'scale']\n",
    "}\n",
    "\n",
    "# run grid search\n",
    "gs = run_svr(X_train, y_train.values.ravel(), cv=5, param_grid=param_grid)\n",
    "\n",
    "# predict\n",
    "result = pd.DataFrame(gs.best_estimator_.predict(X_test), columns=['cnt'])\n",
    "\n",
    "# join id col\n",
    "result = pd.concat([X_test.reset_index()[['id']], result], axis='columns')\n",
    "display(result)\n",
    "\n",
    "# Create SVR filename\n",
    "filename = f'''svr_'''\\\n",
    "           f'''C-{gs.best_estimator_.C}_'''\\\n",
    "           f'''k-{gs.best_estimator_.kernel}_'''\\\n",
    "           f'''e-{gs.best_estimator_.epsilon}_'''\\\n",
    "           f'''g-{gs.best_estimator_.gamma}_'''\\\n",
    "           f'''{dt.datetime.now()}.csv'''\n",
    "\n",
    "result.to_csv('./predictions/bike_sharing_kaggle/' + filename, sep = \",\", index=False)\n",
    "print(f'''Saved as {filename}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch initializing...\n",
      "GradientBoostedRegressor model in training...\n",
      "GradientBoostedRegressor model selected and fitted in 4361.643 s\n",
      "\n",
      "MSE: 1859.38335, RMSE: 43.12057\n",
      "Best parameters selected by GridSearch: {'max_depth': 10, 'min_samples_split': 15, 'n_estimators': 350}\n",
      "Saved as gbdtree_ne-350_md-10_mss-15_2019-01-02 01:53:02.486364.csv\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosted Decision Tree\n",
    "param_fix = {\n",
    "    'learning_rate': .01, \n",
    "    'loss': 'ls'\n",
    "}\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': (1, 10, 100, 200, 350),# 500), \n",
    "    'max_depth': (1, 5, 10, 25),# 50), \n",
    "    'min_samples_split': (2, 5, 15),# 50)\n",
    "}\n",
    "\n",
    "num_samples = 500\n",
    "#X = X_train.iloc[:num_samples, :]\n",
    "#y = y_train.iloc[:num_samples, :].values.ravel()\n",
    "\n",
    "X = X_train\n",
    "y = y_train.values.ravel()\n",
    "\n",
    "gs = run_boosted_tree(X, y, [], [], param_fix=param_fix, cv=10, param_grid=param_grid)\n",
    "\n",
    "#plot_scores(gbt.cv_results_)\n",
    "#plot_training_deviance(gbt, test_data, test_target)\n",
    "\n",
    "# predict\n",
    "result = pd.DataFrame(gs.best_estimator_.predict(X_test), columns=['cnt'])\n",
    "\n",
    "# join id col\n",
    "result = pd.concat([X_test.reset_index()[['id']], result], axis='columns')\n",
    "#display(result)\n",
    "\n",
    "# Create SVR filename\n",
    "filename = f'''gbdtree_'''\\\n",
    "           f'''ne-{gs.best_estimator_.n_estimators}_'''\\\n",
    "           f'''md-{gs.best_estimator_.max_depth}_'''\\\n",
    "           f'''mss-{gs.best_estimator_.min_samples_split}_'''\\\n",
    "           f'''{dt.datetime.now()}.csv'''\n",
    "\n",
    "result.to_csv('./predictions/bike_sharing_kaggle/' + filename, sep = \",\", index=False)\n",
    "print(f'''Saved as {filename}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
